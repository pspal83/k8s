Kubernetes CKA Exam Question.1. Craete a new pod called admin-pod with images busybox. Allow the pod o be able to set system_time. The container should sleep for 3200 seconds.2. A kubeconfig file called test.kubeconfig has been created in /root/TEST. There is something wrong with the configuration. Troubleshoot and fix it.3. Craete a new deployment called web-project-268, with image nginx:1.16 and 1 replica. Next upgrade the deployment to version 1.17 using rolling update. Make sure that the version upgrade is recorded in the resource annotation.4. Monitor the logs of pod foo and: Extract log lines corresponding to error unable-to-access-website Write them to /opt/KULM00201/foo5. List all persistent volumes sorted by capacity, saving the full kubectl output to /opt/KUCC00102/volume_list. Use kubectl 's own functionality for sorting the output, and do not manipulate it any further.6. Ensure a single instance of pod nginx is running on each node of the Kubernetes cluster where nginx also represents the Image name which has to be used. Do not override any taints currently in place.Use DaemonSet to complete this task and use ds-kusc00201 as DaemonSet name.7. Perform the following tasks: Add an init container to hungry-bear (which has been defined in spec file /opt/KUCC00108/pod-spec-KUCC00108.yaml) The init container should create an empty file named/workdir/calm.txt If /workdir/calm.txt is not detected, the pod should exit Once the spec file has been updated with the init container definition, the pod should be created8. Create a pod named kucc8 with a single app container for each of the following images running inside (there may be between 1 and 4 images specified): nginx + redis + memcached.9. Create a new service account with the name pvviewer. Grant this Service account access to list all PersistentVolumes in the cluster by creating an appropriate cluster role called pvviewer-role and ClusterRoleBinding called pvviewer-role-binding.10. 11. Create snapshot of the etcd running at https://127.0.0.1:2379. Save snapshot into /opt/etcd-snapshot.db.12. Create a Persistent Volume with the given specification.13. Taint the worker node to be Unschedulable. Once done, create a pod called dev-redis, image redis:alpine to ensure workloads are not scheduled to this worker node. Finally, create a new pod called prod-redis and image redis:alpine with toleration to be scheduled on node01.14. Set the node named worker node as unavailable and reschedule all the pods running on it. (Drain node)15. Create a Pod called non-root-pod , image: redis:alpine16. Create a NetworkPolicy which denies all ingress traffic17. List all the namespaces in the cluster18. List all the pods in all namespaces19. List all the pods in the particular namespace20. List all the services in the particular namespace21. List all the pods showing name and namespace with a json path expression22. Create an nginx pod in a default namespace and verify the pod running23. Create the same nginx pod with a yaml file24. Output the yaml file of the pod you just created25. Output the yaml file of the pod you just created without the cluster-specific information26. Get the complete details of the pod you just created27. Delete the pod you just created28. Delete the pod you just created without any delay (force delete)29. Create the nginx pod with version 1.17.4 and expose it on port 8030. Change the Image version to 1.15-alpine for the pod you just created and verify the image version is updated31. Change the Image version back to 1.17.1 for the pod you just updated and observe the changes32. Check the Image version without the describe command33. Create the nginx pod and execute the simple shell on the pod34. Get the IP Address of the pod you just created35. Create a busybox pod and run command ls while creating it and check the logs36. If pod crashed check the previous logs of the pod37. Create a busybox pod with command sleep 360038. Check the connection of the nginx pod from the busybox pod39. Create a busybox pod and echo message ‘How are you’ and delete it manually40. Create a busybox pod and echo message ‘How are you’ and have it deleted immediately41. Create an nginx pod and list the pod with different levels of verbosity42. List the nginx pod with custom columns POD_NAME and POD_STATUS43. List all the pods sorted by name44. List all the pods sorted by created timestamp45. Create a Pod with three busy box containers with commands “ls; sleep 3600;”, “echo Hello World; sleep 3600;” and “echo this is the third container; sleep 3600” respectively and check the status46. Check the logs of each container that you just created47. Check the previous logs of the second container busybox2 if any48. Run command ls in the third container busybox3 of the above pod49. Show metrics of the above pod containers and puts them into the file.log and verify50. Create a Pod with main container busybox and which executes this “while true; do echo ‘Hi I am from Main container’ >> /var/log/index.html; sleep 5; done” and with sidecar container with nginx image which exposes on port 80. Use emptyDir Volume and mount this volume on path /var/log for busybox and on path /usr/share/nginx/html for nginx container. Verify both containers are running.51. Exec into both containers and verify that main.txt exist and query the main.txt from sidecar container with curl localhost52. Get the pods with label information53. Create 5 nginx pods in which two of them is labeled env=prod and three of them is labeled env=dev54. Verify all the pods are created with correct labels55. Get the pods with label env=dev56. Get the pods with label env=dev and also output the labels57. Get the pods with label env=prod58. Get the pods with label env=prod and also output the labels59. Get the pods with label env60. Get the pods with labels env=dev and env=prod61. Get the pods with labels env=dev and env=prod and output the labels as well62. Change the label for one of the pod to env=uat and list all the pods to verify63. Remove the labels for the pods that we created now and verify all the labels are removed64. Let’s add the label app=nginx for all the pods and verify65. Get all the nodes with labels (if using minikube you would get only master node)66. Label the node (minikube if you are using) nodeName=nginxnode67. Create a Pod that will be deployed on this node with the label nodeName=nginxnode68. Verify the pod that it is scheduled with the node selector69. Verify the pod nginx that we just created has this label70. Annotate the pods with name=webapp71. Verify the pods that have been annotated correctly72. Remove the annotations on the pods and verify73. Remove all the pods that we created so far74. Create a deployment called webapp with image nginx with 5 replicas75. Get the deployment you just created with labels76. Output the yaml file of the deployment you just created77. Get the pods of this deployment78. Scale the deployment from 5 replicas to 20 replicas and verify79. Get the deployment rollout status80. Get the replicaset that created with this deployment81. Get the yaml of the replicaset and pods of this deployment82. Delete the deployment you just created and watch all the pods are also being deleted83. Create a deployment of webapp with image nginx:1.17.1 with container port 80 and verify the image version84. Update the deployment with the image version 1.17.4 and verify85. Check the rollout history and make sure everything is ok after the update86. Undo the deployment to the previous version 1.17.1 and verify Image has the previous version87. Update the deployment with the image version 1.16.1 and verify the image and also check the rollout history88. Update the deployment to the Image 1.17.1 and verify everything is ok89. Update the deployment with the wrong image version 1.100 and verify something is wrong with the deployment90. Undo the deployment with the previous version and verify everything is Ok91. Check the history of the specific revision of that deployment92. Pause the rollout of the deployment93. Update the deployment with the image version latest and check the history and verify nothing is going on94. Resume the rollout of the deployment95. Check the rollout history and verify it has the new version96. Apply the autoscaling to this deployment with minimum 10 and maximum 20 replicas and target CPU of 85% and verify hpa is created and replicas are increased to 10 from 197. Clean the cluster by deleting deployment and hpa you just created98. Create a Job with an image node which prints node version and also verifies there is a pod created for this job99. Get the logs of the job just created100. Output the yaml file for the Job with the image busybox which echos “Hello I am from job”101. Copy the above YAML file to hello-job.yaml file and create the job102. Verify the job and the associated pod is created and check the logs as well103. Delete the job we just created104. Create the same job and make it run 10 times one after one105. Watch the job that runs 10 times one by one and verify 10 pods are created and delete those after it’s completed106. Create the same job and make it run 10 times parallel107. Watch the job that runs 10 times parallelly and verify 10 pods are created and delete those after it’s completed108. Create a Cronjob with busybox image that prints date and hello from kubernetes cluster message for every minute109. Output the YAML file of the above cronjob110. Verify that CronJob creating a separate job and pods for every minute to run and verify the logs of the pod111. Delete the CronJob and verify all the associated jobs and pods are also deleted.112. List Persistent Volumes in the cluster113. Create a hostPath PersistentVolume named task-pv-volume with storage 10Gi, access modes ReadWriteOnce, storageClassName manual, and volume at /mnt/data and verify114. Create a PersistentVolumeClaim of at least 3Gi storage and access mode ReadWriteOnce and verify status is Bound115. Delete persistent volume and PersistentVolumeClaim we just created116. Create a Pod with an image Redis and configure a volume that lasts for the lifetime of the Pod117. Exec into the above pod and create a file named file.txt with the text ‘This is called the file’ in the path /data/redis and open another tab and exec again with the same pod and verifies file exist in the same path.118. Delete the above pod and create again from the same yaml file and verifies there is no file.txt in the path /data/redis119. Create PersistentVolume named task-pv-volume with storage 10Gi, access modes ReadWriteOnce, storageClassName manual, and volume at /mnt/data and Create a PersistentVolumeClaim of at least 3Gi storage and access mode ReadWriteOnce and verify status is Bound120. Create an nginx pod with containerPort 80 and with a PersistentVolumeClaim task-pv-claim and has a mouth path "/usr/share/nginx/html"121. List all the configmaps in the cluster122. Create a configmap called myconfigmap with literal value appname=myapp123. Verify the configmap we just created has this data124. delete the configmap myconfigmap we just created125. Create a file called config.txt with two values key1=value1 and key2=value2 and verify the file126. Create a configmap named keyvalcfgmap and read data from the file config.txt and verify that configmap is created correctly127. Create an nginx pod and load environment values from the above configmap keyvalcfgmap and exec into the pod and verify the environment variables and delete the pod128. Create an env file file.env with var1=val1 and create a configmap envcfgmap from this env file and verify the configmap129. Create an nginx pod and load environment values from the above configmap envcfgmap and exec into the pod and verify the environment variables and delete the pod130. Create a configmap called cfgvolume with values var1=val1, var2=val2 and create an nginx pod with volume nginx-volume which reads data from this configmap cfgvolume and put it on the path /etc/cfg131. Create a pod called secbusybox with the image busybox which executes command sleep 3600 and makes sure any Containers in the Pod, all processes run with user ID 1000 and with group id 2000 and verify.132. Create the same pod as above this time set the securityContext for the container as well and verify that the securityContext of container overrides the Pod level securityContext.133. Create pod with an nginx image and configure the pod with capabilities NET_ADMIN and SYS_TIME verify the capabilities134. Create a Pod nginx and specify a memory request and a memory limit of 100Mi and 200Mi respectively.135. Create a Pod nginx and specify a CPU request and a CPU limit of 0.5 and 1 respectively.136. Create a Pod nginx and specify both CPU, memory requests and limits together and verify.137. Create a Pod nginx and specify a memory request and a memory limit of 100Gi and 200Gi respectively which is too big for the nodes and verify pod fails to start because of insufficient memory138. Create a secret mysecret with values user=myuser and password=mypassword139. List the secrets in all namespaces140. Output the yaml of the secret created above141. Create an nginx pod which reads username as the environment variable142. Create an nginx pod which loads the secret as environment variables143. List all the service accounts in the default namespace144. List all the service accounts in all namespaces145. Create a service account called admin146. Output the YAML file for the service account we just created147. Create a busybox pod which executes this command sleep 3600 with the service account admin and verify148. Create an nginx pod with containerPort 80 and it should only receive traffic only it checks the endpoint / on port 80 and verify and delete the pod.149. Create an nginx pod with containerPort 80 and it should check the pod running at endpoint / healthz on port 80 and verify and delete the pod.150. Create an nginx pod with containerPort 80 and it should check the pod running at endpoint /healthz on port 80 and it should only receive traffic only it checks the endpoint / on port 80. verify the pod.151. Check what all are the options that we can configure with readiness and liveness probes152. Create the pod nginx with the above liveness and readiness probes so that it should wait for 20 seconds before it checks liveness and readiness probes and it should check every 25 seconds.153. Create a busybox pod with this command “echo I am from busybox pod; sleep 3600;” and verify the logs.154. copy the logs of the above pod to the busybox-logs.txt and verify155. List all the events sorted by timestamp and put them into file.log and verify156. Create a pod with an image alpine which executes this command ”while true; do echo ‘Hi I am from alpine’; sleep 5; done” and verify and follow the logs of the pod.157. Create the pod with this kubectl create -f https://gist.githubusercontent.com/bbachi/212168375b39e36e2e2984c097167b00/raw/1fd63509c3ae3a3d3da844640fb4cca744543c1c/not-running.yml. The pod is not in the running state. Debug it.158. This following yaml creates 4 namespaces and 4 pods. One of the pod in one of the namespaces are not in the running state. Debug and fix it. https://gist.githubusercontent.com/bbachi/1f001f10337234d46806929d12245397/raw/84b7295fb077f15de979fec5b3f7a13fc69c6d83/problem-pod.yaml.159. Get the memory and CPU usage of all the pods and find out top 3 pods which have the highest usage and put them into the cpu-usage.txt file160. Create an nginx pod with a yaml file with label my-nginx and expose the port 80161. Create the service for this nginx pod with the pod selector app: my-nginx162. Find out the label of the pod and verify the service has the same label163. Delete the service and create the service with kubectl expose command and verify the label164. Delete the service and create the service again with type NodePort165. Create the temporary busybox pod and hit the service. Verify the service that it should return the nginx page index.html.166. Create a NetworkPolicy which denies all ingress traffic